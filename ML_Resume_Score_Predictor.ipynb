{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ZAz7WFRueQwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "obl_dDuHgHkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Datasets/UpdatedResumeDataSet[1].csv')"
      ],
      "metadata": {
        "id": "GjtWZcSzgUob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data, '\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF7Trdg2g_0o",
        "outputId": "bbe5e134-8717-4da1-e027-b32375a1dda0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Category                                             Resume\n",
            "0    Data Science  Skills * Programming Languages: Python (pandas...\n",
            "1    Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
            "2    Data Science  Areas of Interest Deep Learning, Control Syste...\n",
            "3    Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
            "4    Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...\n",
            "..            ...                                                ...\n",
            "957       Testing  Computer Skills: â¢ Proficient in MS office (...\n",
            "958       Testing  â Willingness to accept the challenges. â ...\n",
            "959       Testing  PERSONAL SKILLS â¢ Quick learner, â¢ Eagerne...\n",
            "960       Testing  COMPUTER SKILLS & SOFTWARE KNOWLEDGE MS-Power ...\n",
            "961       Testing  Skill Set OS Windows XP/7/8/8.1/10 Database MY...\n",
            "\n",
            "[962 rows x 2 columns] \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['Category'].unique())\n",
        "print(len(data['Category'].unique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojaJa9ljj4A5",
        "outputId": "3c1a6b97-ddb5-4aaf-cfd5-4e0da5e393e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Data Science' 'HR' 'Advocate' 'Arts' 'Web Designing'\n",
            " 'Mechanical Engineer' 'Sales' 'Health and fitness' 'Civil Engineer'\n",
            " 'Java Developer' 'Business Analyst' 'SAP Developer' 'Automation Testing'\n",
            " 'Electrical Engineering' 'Operations Manager' 'Python Developer'\n",
            " 'DevOps Engineer' 'Network Security Engineer' 'PMO' 'Database' 'Hadoop'\n",
            " 'ETL Developer' 'DotNet Developer' 'Blockchain' 'Testing']\n",
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(data['Resume'].unique())\n",
        "print(len(data['Resume'].unique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnPJ4o0ukLnu",
        "outputId": "8c740d04-e585-4b81-8f39-f024039d7427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuE5Xgj2jAZC",
        "outputId": "11d766af-d7e4-4425-8c17-65fbc2c2d8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Category                                             Resume\n",
            "count              962                                                962\n",
            "unique              25                                                166\n",
            "top     Java Developer  Technical Skills Web Technologies: Angular JS,...\n",
            "freq                84                                                 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The number of NaN','\\n', np.sum(data.isnull()), '\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUSCPsxgi8Hs",
        "outputId": "c235b741-6bb0-4373-dc79-6313aff7ca76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of NaN \n",
            " Category    0\n",
            "Resume      0\n",
            "dtype: int64 \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('features: ', data.columns, '\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFdLE4fCi5fd",
        "outputId": "d07d69b8-7be3-4293-94b5-eb0de12fc64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features:  Index(['Category', 'Resume'], dtype='object') \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data['Resume'], data['Category'], test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "Gj6dFepCke4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s-VoqpxeJvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0093ee53-d40f-4741-f986-d76d93b27c93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['000' '01' '017' ... 'zz' 'ã¼' 'ã¼â']\n",
            "(644, 7513)\n"
          ]
        }
      ],
      "source": [
        "#Vectorizing with tf-idf\n",
        "vectorizer = TfidfVectorizer(lowercase=True, analyzer='word')\n",
        "X_train_tf_idf = vectorizer.fit_transform(X_train)\n",
        "X_test_tf_idf = vectorizer.transform(X_test)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X_train_tf_idf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)  # y_train: list of string labels\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=500)\n",
        "clf.fit(X_train_tf_idf, y_train_encoded)\n",
        "\n",
        "preds = clf.predict(X_test_tf_idf)\n",
        "\n",
        "acc = accuracy_score(y_test_encoded, preds)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_encoded, preds, target_names=label_encoder.classes_))\n",
        "\n",
        "decoded_preds = label_encoder.inverse_transform(preds)\n",
        "print(\"Example decoded predictions:\", decoded_preds[:5])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGAJixnXwXlQ",
        "outputId": "332bf079-dbca-44d3-870c-2f369aa79987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9937\n",
            "\n",
            "Classification Report:\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "                 Advocate       1.00      1.00      1.00         7\n",
            "                     Arts       1.00      1.00      1.00        10\n",
            "       Automation Testing       1.00      1.00      1.00         7\n",
            "               Blockchain       1.00      1.00      1.00        12\n",
            "         Business Analyst       1.00      1.00      1.00         9\n",
            "           Civil Engineer       1.00      1.00      1.00        14\n",
            "             Data Science       1.00      1.00      1.00        12\n",
            "                 Database       1.00      1.00      1.00         9\n",
            "          DevOps Engineer       1.00      0.90      0.95        21\n",
            "         DotNet Developer       1.00      1.00      1.00        11\n",
            "            ETL Developer       1.00      1.00      1.00         9\n",
            "   Electrical Engineering       1.00      1.00      1.00        10\n",
            "                       HR       1.00      1.00      1.00        18\n",
            "                   Hadoop       1.00      1.00      1.00        10\n",
            "       Health and fitness       1.00      1.00      1.00        10\n",
            "           Java Developer       1.00      1.00      1.00        30\n",
            "      Mechanical Engineer       1.00      1.00      1.00        13\n",
            "Network Security Engineer       1.00      1.00      1.00         6\n",
            "       Operations Manager       1.00      1.00      1.00        18\n",
            "                      PMO       0.90      1.00      0.95         9\n",
            "         Python Developer       1.00      1.00      1.00        16\n",
            "            SAP Developer       1.00      1.00      1.00        10\n",
            "                    Sales       1.00      1.00      1.00        12\n",
            "                  Testing       1.00      1.00      1.00        27\n",
            "            Web Designing       0.89      1.00      0.94         8\n",
            "\n",
            "                 accuracy                           0.99       318\n",
            "                macro avg       0.99      1.00      0.99       318\n",
            "             weighted avg       0.99      0.99      0.99       318\n",
            "\n",
            "Example decoded predictions: ['Java Developer' 'Java Developer' 'Java Developer' 'Hadoop'\n",
            " 'Health and fitness']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text encoding with bert\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "yPR7INdu5Fhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05111794-9796-41c0-8e40-31e8e1e37be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# Load BERT\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def get_bert_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Get CLS token\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :]  # shape: (1, 768)\n",
        "    return cls_embedding.cpu().numpy().flatten()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s84sQzcuUkEQ",
        "outputId": "39ffb996-0bdd-444d-98de-88e57823193f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_bert = np.array([get_bert_embedding(text) for text in tqdm(X_train)])\n",
        "X_test_bert = np.array([get_bert_embedding(text) for text in tqdm(X_test)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_PlZnkCU0wa",
        "outputId": "528ab43a-88af-4058-d074-cdecc0df33cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 644/644 [00:46<00:00, 14.00it/s]\n",
            "100%|██████████| 318/318 [00:19<00:00, 16.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_test_enc = le.transform(y_test)\n",
        "\n",
        "logreg_bert = LogisticRegression(max_iter=1000)\n",
        "logreg_bert.fit(X_train_bert, y_train_enc)\n",
        "\n",
        "preds = logreg_bert.predict(X_test_bert)\n",
        "print(\"BERT+LogReg Accuracy:\", accuracy_score(y_test_enc, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "866QQK2kU8h5",
        "outputId": "3a872d6a-f353-4ac0-83c5-5422e03314ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT+LogReg Accuracy: 0.9937106918238994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"mlp_model.pt\")"
      ],
      "metadata": {
        "id": "9_cCYH10YK-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zS7t9XVaYVow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save TF-IDF vectorizer\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
        "\n",
        "# Save label encoder (for transforming labels to/from numbers)\n",
        "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
        "\n",
        "# Save logistic regression trained on TF-IDF features\n",
        "joblib.dump(clf, \"logreg_tfidf.pkl\")\n",
        "\n",
        "# Save logistic regression trained on BERT embeddings\n",
        "joblib.dump(logreg_bert, \"logreg_bert.pkl\")"
      ],
      "metadata": {
        "id": "0B9YGWtDYaTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb02bc1f-9d9e-41cf-9b8b-6e4deb1331ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['logreg_bert.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"logistic_model.pkl\")\n",
        "files.download(\"tfidf_vectorizer.pkl\")\n",
        "files.download(\"logreg_bert.pkl\")\n",
        "files.download(\"label_encoder.pkl\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KxnvoAwXf_9T",
        "outputId": "3ff2d91d-819f-453d-b586-0b773c1d28a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7ff95da2-126f-456f-ac5c-aa415813adad\", \"logistic_model.pkl\", 1503855)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_25419259-affc-40b8-a711-384e4b5a2031\", \"tfidf_vectorizer.pkl\", 157557)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_49e048bd-eb95-40ed-ad41-7f78c699420f\", \"logreg_bert.pkl\", 154847)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b0135469-82fc-476a-b064-a809ef44b406\", \"label_encoder.pkl\", 863)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}